{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix2pix_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1QtDMXqDWz1J6-fPxgShpw67W3hC2cznf",
      "authorship_tag": "ABX9TyMf/aI8RlJsEq3sAcoZ3AVd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kairavkkp/ML-Tutorials/blob/pix2pix/pix2pix/pix2pix_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QUjnnFvemDK"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10USk4tffAVJ",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "07ef2b90-a5bf-4309-a0ad-63c6b3267e24"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bcaaccd3-f158-4b3b-8a70-e8f6a2960523\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bcaaccd3-f158-4b3b-8a70-e8f6a2960523\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"sagarjiyani\",\"key\":\"03e058eeaa881793908f116aafb89e22\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BJhLGPIfKiF"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSzCCbaBfblu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40512530-4e53-4e5c-b488-c122eb8e172c"
      },
      "source": [
        "! kaggle datasets download -d vikramtiwari/pix2pix-dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pix2pix-dataset.zip to /content\n",
            "100% 2.39G/2.40G [01:12<00:00, 46.9MB/s]\n",
            "100% 2.40G/2.40G [01:12<00:00, 35.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fkZlBiTfboo"
      },
      "source": [
        "! unzip pix2pix-dataset.zip -d /content/drive/MyDrive/ColabNotebooks/GANs/pix2pix/maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxh24qyp10-U"
      },
      "source": [
        "!pip install --upgrade albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwd5oYEnhHwW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.utils import save_image\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngCCglC1WCm8"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/ColabNotebooks/GANs/pix2pix/maps/maps/maps'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VliW_1eMp-cx"
      },
      "source": [
        "# Descriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4QHVevAhGru"
      },
      "source": [
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride=2):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding_mode='reflect'),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "  \n",
        "class Descriminator(nn.Module):\n",
        "  def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "    super().__init__()\n",
        "    self.initial = nn.Sequential(\n",
        "        nn.Conv2d(in_channels*2, features[0], kernel_size=4, stride=2, padding=1, padding_mode='reflect'),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "    layers=[]\n",
        "    in_channels = features[0]\n",
        "    for feature  in features[1:]:\n",
        "      layers.append(\n",
        "          CNNBlock(in_channels, feature , stride=1 if feature  == features[-1] else 2)\n",
        "      )\n",
        "      in_channels = feature \n",
        "\n",
        "    layers.append(\n",
        "        nn.Conv2d(in_channels, 1, kernel_size=4, padding=1, padding_mode='reflect')\n",
        "    )\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "  \n",
        "  def forward(self, x, y):\n",
        "     x = torch.cat([x, y], dim=1)\n",
        "     x = self.initial(x)\n",
        "     x = self.model(x)\n",
        "     return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVx_MmIIqri3"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8bXl7-4qu8o"
      },
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.down = down\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=64):\n",
        "        super().__init__()\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down2 = Block(features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down3 = Block(features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down4 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down5 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down6 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(features * 8, features * 8, 4, 2, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up2 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up3 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up4 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up5 = Block(features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up6 = Block(features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "        final_up = self.final_up(torch.cat([up7, d1], 1))\n",
        "        return final_up"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAT_Kewi1_F3"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa_BXjdhcuXv"
      },
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "LEARNING_RATE = 2e-4\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 2\n",
        "IMG_SIZE = 256\n",
        "CHANNELS = 3\n",
        "L1_LAMBDA = 100\n",
        "NUM_EPOCHS = 20\n",
        "LOAD_MODEL =False\n",
        "SAVE_MODEL =True\n",
        "CHECKPOINT_DISC = '/content/drive/MyDrive/ColabNotebooks/GANs/pix2pix/checkpoints/disc.pth.tar'\n",
        "CHECKPOINT_GEN = '/content/drive/MyDrive/ColabNotebooks/GANs/pix2pix/checkpoints/gen.pth.tar'\n",
        "\n",
        "both_transform = A.Compose(\n",
        "    [\n",
        "     A.Resize(width=256, height=256), \n",
        "     A.HorizontalFlip(p=0.5)\n",
        "    ],\n",
        "    additional_targets = {'image0' : 'image'},\n",
        ")\n",
        "\n",
        "transform_only_input = A.Compose(\n",
        "    [\n",
        "     A.HorizontalFlip(p=0.5),\n",
        "     A.ColorJitter(p=0.2),\n",
        "     A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0),\n",
        "     ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_only_mask = A.Compose(\n",
        "    [\n",
        "     A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5 ,0.5], max_pixel_value=255.0),\n",
        "     ToTensorV2(),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntwgvT9C2EGC"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2bYlf-UpCc8"
      },
      "source": [
        "def save_some_example(gen, val_loader, epoch, folder):\n",
        "  x, y = next(iter(val_loader))\n",
        "  x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "  gen.eval()\n",
        "  with torch.no_grad():\n",
        "    y_fake = gen(x)\n",
        "    y_fake = y_fake * 0.5 + 0.5\n",
        "    save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
        "    save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n",
        "    if epoch == 1:\n",
        "      save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
        "  gen.train()\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename='/content/drive/MyDrive/ColabNotebooks/GANs/pix2pix/checkpoints/my_checkpoint.pth.tar'):\n",
        "  print('=> Saving Checkpoint')\n",
        "  checkpoint = {\n",
        "      'state_dict' : model.state_dict(),\n",
        "      'optimizer' : optimizer.state_dict(),\n",
        "  }\n",
        "  torch.save(checkpoint, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "  print('=> Loading Checkpoint')\n",
        "  checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
        "  model.load_state_dict(checpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checpoint['optimizer'])\n",
        "\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_0zUevkVuz-"
      },
      "source": [
        "# Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkCaDu94WEZM"
      },
      "source": [
        "class MapDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.list_files = os.listdir(self.root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_file = self.list_files[index]\n",
        "        img_path = os.path.join(self.root_dir, img_file)\n",
        "        image = np.array(Image.open(img_path))\n",
        "        input_image = image[:, :600, :]\n",
        "        target_image = image[:, 600:, :]\n",
        "\n",
        "        augmentations = both_transform(image=input_image, image0=target_image)\n",
        "        input_image = augmentations[\"image\"]\n",
        "        target_image = augmentations[\"image0\"]\n",
        "\n",
        "        input_image = transform_only_input(image=input_image)[\"image\"]\n",
        "        target_image = transform_only_mask(image=target_image)[\"image\"]\n",
        "\n",
        "        return input_image, target_image"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZveQpck7zkmZ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdBEOf3B0M-3",
        "outputId": "54a5049b-9ca4-4ac0-e0ac-76b17f01f637"
      },
      "source": [
        "def train_fn(disc, gen, loader, opt_disc, opt_gen, l1, bce, g_scalar, d_scalar):\n",
        "  loop = tqdm(loader, leave=True)\n",
        "  \n",
        "  for idx, (x, y) in enumerate(loader):\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "    # Train Discriminator\n",
        "    with torch.cuda.amp.autocast():\n",
        "      y_fake = gen(x)\n",
        "      D_real = disc(x, y)\n",
        "      D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
        "      D_fake = disc(x, y_fake.detach())\n",
        "      D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
        "      D_loss = (D_real_loss + D_fake_loss) / 2\n",
        "\n",
        "    disc.zero_grad()\n",
        "    d_scalar.scale(D_loss).backward()\n",
        "    d_scalar.step(opt_disc)\n",
        "    d_scalar.update()\n",
        "\n",
        "    # Train Generator\n",
        "    with torch.cuda.amp.autocast():\n",
        "      D_fake = disc(x, y_fake)\n",
        "      G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
        "      L1 = l1(y_fake, y) * L1_LAMBDA\n",
        "      G_loss = G_fake_loss + L1\n",
        "\n",
        "    opt_gen.zero_grad()\n",
        "    g_scalar.scale(G_loss).backward()\n",
        "    g_scalar.step(opt_gen)\n",
        "    g_scalar.update()\n",
        "\n",
        "def main():\n",
        "  disc = Descriminator(in_channels=3).to(DEVICE)\n",
        "  gen = Generator(in_channels=3, features=64).to(DEVICE)\n",
        "  opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "  opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "  BCE = nn.BCEWithLogitsLoss()\n",
        "  L1_LOSS = nn.L1Loss()\n",
        "\n",
        "  if LOAD_MODEL:\n",
        "    load_checkpoint(CHECKPOINT_GEN, gen, opt_gen, LEARNING_RATE)\n",
        "    load_checkpoint(CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE)\n",
        "    \n",
        "  train_dataset = MapDataset(root_dir=os.path.join(PATH, 'train'))\n",
        "  train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        " \n",
        "  g_scalar = torch.cuda.amp.GradScaler()\n",
        "  d_scalar = torch.cuda.amp.GradScaler()\n",
        "\n",
        "  val_dataset = MapDataset(root_dir=os.path.join(PATH, 'val'))\n",
        "  val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "  \n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    train_fn(disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scalar, d_scalar)\n",
        "\n",
        "    if SAVE_MODEL and epoch % 10 == 0:\n",
        "      save_checkpoint(gen, opt_gen, CHECKPOINT_GEN)\n",
        "      save_checkpoint(disc, opt_disc, CHECKPOINT_DISC)\n",
        "\n",
        "    save_some_example(gen, val_loader, epoch, folder='/content/drive/MyDrive/ColabNotebooks/GANs/pix2pix/evaluation')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=> Saving Checkpoint\n",
            "=> Saving Checkpoint\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=> Saving Checkpoint\n",
            "=> Saving Checkpoint\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prnhrUbddogg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}