{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_transformer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kairavkkp/ML-Tutorials/blob/basic-transformers/Basic-Transformer/basic_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh8bhj25_JUQ"
      },
      "source": [
        "# Basic Transformer\n",
        "\n",
        "[Link](https://www.tensorflow.org/tutorials/text/transformer) to original tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLtkyY9CHWhj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wx_DxxIFaH-",
        "outputId": "4d520f75-adbc-4e06-f70e-e80eb842f442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr  1 06:19:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    71W / 149W |    124MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1QyRYeJ_JxQ",
        "outputId": "055a9035-b9b3-4832-a3e7-418acf876310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q tensorflow_text"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4MB 4.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yCODRy8D_NX"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import sys\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA8X-Ya4H9co"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Basic-Transformer')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAKgsXXzD_Kg"
      },
      "source": [
        "## Suppress Tensorflow warnings\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-QozTygEhr1"
      },
      "source": [
        "# Dataset Download\n",
        "# Portugese to English word translation\n",
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
        "\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZTekUqMEhof",
        "outputId": "efcc6234-bac7-45d0-fea1-342d94b24e57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Snippet of what train_example looks like\n",
        "for pt_examples, en_examples in train_examples.batch(1).take(1):\n",
        "\n",
        "  print(\"Portuguese Example:\")\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "\n",
        "  print(\"\\nEnglish Example:\")\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Portuguese Example:\n",
            "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
            "\n",
            "English Example:\n",
            "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4xE8DCIEhk6",
        "outputId": "04e54eb0-dc6d-4c02-b4d8-82162c9166ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Tokennization and detokenization\n",
        "\n",
        "model_name = \"ted_hrlr_translate_pt_en_converter\"\n",
        "tf.keras.utils.get_file(f\"{model_name}.zip\",\n",
        "                        f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n",
        "                        cache_dir='.', cache_subdir='.', extract=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n",
            "188416/184801 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'././ted_hrlr_translate_pt_en_converter.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJQhi_gaEhZx"
      },
      "source": [
        "# Loading the tokenizers from the downloaded model\n",
        "tokenizers = tf.saved_model.load(model_name)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an-QuIQzIRyy",
        "outputId": "451803c3-d490-41a0-b047-07d1c8df9af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's look at the methods inherited by the Tokenizers\n",
        "\n",
        "# This is for the English tokenizer\n",
        "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['detokenize',\n",
              " 'get_reserved_tokens',\n",
              " 'get_vocab_path',\n",
              " 'get_vocab_size',\n",
              " 'lookup',\n",
              " 'tokenize',\n",
              " 'tokenizer',\n",
              " 'vocab']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjjd9GArIRvt",
        "outputId": "1f275c80-6338-4dbe-d0d2-6f8510d3e034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This is for the Portuguese tokenizer\n",
        "[item for item in dir(tokenizers.pt) if not item.startswith('_')]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['detokenize',\n",
              " 'get_reserved_tokens',\n",
              " 'get_vocab_path',\n",
              " 'get_vocab_size',\n",
              " 'lookup',\n",
              " 'tokenize',\n",
              " 'tokenizer',\n",
              " 'vocab']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvoSiiefJD7l"
      },
      "source": [
        "As we can see both the tokenizers inherit same methods. It'll be easy for us to perform similar operations on each texts in parallel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoQcuJv4IRrW",
        "outputId": "b34790c5-eb1d-4481-a0a6-8f1b64638df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Let's tokenize this string.\\n\")\n",
        "\n",
        "print(\"Non Tokenized String: \")\n",
        "for en in en_examples.numpy():\n",
        "  print(en.decode('utf-8'))\n",
        "\n",
        "print()\n",
        "\n",
        "# Encoding the string\n",
        "encoded = tokenizers.en.tokenize(en_examples)\n",
        "\n",
        "print(\"Tokenized string: \")\n",
        "for row in encoded.to_list():\n",
        "  print(row)\n",
        "print()\n",
        "\n",
        "print('Now, lets try to detokenize the string and see if we get back the original string back.\\n')\n",
        "\n",
        "# Decoding the string\n",
        "decoded = tokenizers.en.detokenize(encoded)\n",
        "\n",
        "print('Detokenized String:')\n",
        "for row in decoded.numpy():\n",
        "  print(row.decode('utf-8'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's tokenize this string.\n",
            "\n",
            "Non Tokenized String: \n",
            "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
            "\n",
            "Tokenized string: \n",
            "[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n",
            "\n",
            "Now, lets try to detokenize the string and see if we get back the original string back.\n",
            "\n",
            "Detokenized String:\n",
            "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Td3un-kIRoO",
        "outputId": "0493a26d-266b-4e1e-8bdf-6a5bee5a5657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## We can use the lookup method to get the token-text from token-IDs\n",
        "\n",
        "tokens = tokenizers.en.lookup(encoded)\n",
        "tokens"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability', b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage', b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip', b'##ity', b'.', b'[END]']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPs4dwWwLDAK"
      },
      "source": [
        "We can see that the word `searchability` is tokenized in a sub-word manner. It is comprised of two tokens, namely `search` and `##ability`. Similarly it is the same for `serendipity`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUYRSeskLcdx"
      },
      "source": [
        "## Setup Input pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fM2mlxjIRhH"
      },
      "source": [
        "def tokenize_pairs(pt, en):\n",
        "  pt = tokenizers.pt.tokenize(pt)\n",
        "  pt = pt.to_tensor()\n",
        "\n",
        "  en = tokenizers.en.tokenize(en)\n",
        "  en = en.to_tensor()\n",
        "\n",
        "  return pt, en"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfoR-_dhIRd7"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsdKoZbFIRaf"
      },
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds.cache()\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        "  )"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ryjRZkQIRXG"
      },
      "source": [
        "# Preparing batches for Training and Validation\n",
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_EAHUuiMzDO"
      },
      "source": [
        "As we know that Transformers have a disadvantage that if the training set like text, doesn't have any positional encoding the transformers will just treat them as Bag of Words.\n",
        "\n",
        "### Positional Encoding\n",
        "\n",
        "$$PE_{(pos,2i)} = sin(pos/10000^{2i/d_{model}})$$\n",
        "\n",
        "$$PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jGtsXArIRII"
      },
      "source": [
        "# Creating Positional Encoding for the train examples.\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  ## handling PE for Even indices\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # handling PE for Odd indices\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLvQYUStQAQ1",
        "outputId": "bf8d3f53-7594-4251-e46c-780839ae6e33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n, d = 2048, 512\n",
        "pos_encoding = positional_encoding(n, d)\n",
        "pos_encoding = pos_encoding[0]\n",
        "pos_encoding.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2048, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtjZxZwsQDuD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3u-vUKcQAOL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz5P6F2rQACR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}